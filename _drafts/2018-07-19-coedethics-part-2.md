Last Friday I attended the CoedEthics conference, organised by Ann Currie and her team. This was the first conference of its kind about ethics.

To recap, Ann posed these questions to those of us who write software for a living:

* Is there a problem with ethics?
* What can I as a software engineer do about it?
* What might stop me from doing that?
* What might get in my way?
* And how might I get over that?

I wrote about Cori Crider's talk previously.

[Caitlin McDonald](https://twitter.com/cmcd_phd) talked about being a **Data Citizen** and the [Data Ethics Canvas](https://theodi.org/article/data-ethics-canvas) that can be injected into the work that we do. Government Digital Services has also released a [Data Science Ethical Framework](https://gds.blog.gov.uk/2017/11/27/updating-the-data-science-ethical-framework/).

Cathy O'Neill's book [Weapons of Math Destruction](https://weaponsofmathdestructionbook.com/) talks about the impact of algorithms that on modern life, which lack transparency.

Caitlin draws parallels between how citizens interact with the law, and how data citizens interact with data science. _How can we as data citizens push for more effective and fair data science, which impacts us? A first step might be insisting on the same level of transparency for ethical data practices in data science as there are in law.

You have to [treat data like people](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005399), because most metadata is about people.

Caitlin's talk will be posted on InfoQ. In the meantime here is an [earlier version](https://www.infoq.com/articles/data-ethics).

**Data Science in Action**: Emma Prest and Clare Kiching talks about [Data Kind UK's](https://gds.blog.gov.uk/2017/11/27/updating-the-data-science-ethical-framework/) work. Data Kind is a charity that does pro bono data science work for good.

What happens when you start off with the best of intentions?

An app to track potholes can lead to potholes being fixed in richer areas only because residents have smartphones. The Samaritans' Radar app was launched with the intention of helping users who were posting tweets that suggested suicidal thoughts; it was [suspended](https://www.theguardian.com/society/2014/nov/07/samaritans-radar-app-suicide-watch-privacy-twitter-users) following privacy concerns.

When starting a project:

1. Embed ethics discussions in your project process: at kick-off, discussing data and results, planning implementation

2. Involve a diverse range of people: client, data scientists, developers, users to get a fuller picture of the context and risks. Data scientists are never experts in the subject matter. And the users ... bring them in earlier.

3. Think about explanability. Will your clients be able to understand the model and explain decisions to end users?

4. Project intent matters. But also consider the unexpected consequences.

[Andrea Dobson](https://twitter.com/andrea_kock?lang=en)'s topic was **Ethics: A psychological perspective**. 

Why do good people make bad decision?

If you have to report an ethical issue would you prefer to conform to the rest of the group?

In less clear situations, levels of conformity increase.

In 1997 a Korean Air flight [crashed](https://news.nationalgeographic.com/news/2013/07/130709-asiana-flight-214-crash-korean-airlines-culture-outliers/), killing 223 people because the co-pilot was afraid to question the poor judgement of the pilot.

Andrea talked about [Milgram's experiment](https://en.wikipedia.org/wiki/Milgram_experiment) and the notion of psychological safety, which allows people to feel able to speak up.

Here's Amy Edmondson on _Building a psychologically safe workplace_.

<iframe width="560" height="315" src="https://www.youtube.com/embed/LhoLuui9gX8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

[Yanqing Cheng](https://twitter.com/YanqingCheng) [(InfoQ)](https://www.infoq.com/profile/Yanqing-Cheng) asked _Why do we care about ethics?_  We care about ethics because we want the world to be a better place. What makes the world a better place?

Many of us create technology with positive impact. 

What makes the world better but doesn't feel morally good?

Human intuitions don't scale ... we can do a huge amount of good but becuase of [scope insensitivity bias](https://www.lesswrong.com/posts/2ftJ38y9SRBCBsCzy/scope-insensitivity) we don't feel good enough about doing it. 

<hr/>
Up to here.

Effective Altruism "how can we use our limited resource to best help others?"

Looking at charity organisations on how bst to use resources.

The NHS is prepapred to sned Â£20,000 per QALY.

Distributions of condoms is an effective way to prevent spread of HIV.

How do you maximise the effect of your personal donations?

Look up Giving What We Can and GiveWell.

Malaria is no longer the leading killer of people in Afria.

The most effective actions are not always the most intuitive.

No Lean Season ... low interest loan for a bus ticket so they can get to Dhaka and work there as a rickshaw driver.

Our takeaway: prioritise good actions at scale.

The Impact of our Actions - we care about ethics because we want the world to be a better place.

Who - How - What model

1. Who can have an impact on your goal?
2. How can they help/obstruct?
3. What can you do to affect their behaviour?

Heroic Responsibility:
Harry Potter and the Methods of Rationality "You've got to get the job done no matter what."

Responsibility means:
- think once, then think twice (on whether your biases are affecting the sitaution) and think hard
- focus on what you (personally) can do
- have courage
- remember that you have the power

**Harry Trimble Power, ethics and design education**
projectsbyif.com


Recognising power in the things we build

It's getting harder to tell design and software developmnt apart

Richard Pope: "Software is politics now". Because software is power.

Today so much power in society lies with designing and building software.

Stephen McCarty "Designers as power brokers" - blog post

Design is a position of power. Designers need to reconigse the power relationships in the things they build.

Applying ethics

George Ay... 'Design Education's Big Gap: Understanding the Role of Power'

https://www.linkedin.com/in/georgeaye/

Ethical decisions are often unavoidable.

Authentication. Giving consent to share data.

Open APIs in the telecoms sector could create powerful new services.

Bills Box 

Let's you make informed decisions up front.

Exploring consent and data minimisation for people affected by humanitarian crisis.

IF developed prototypes to inform conversations.

Give consent receipts.

Machine intelligence is increasingly entering important areas of our lives.

We need a shared language to talk about ethics.

giving somethign a name helps us talk about it better.

Data Permissions Catalogue ... has different patterns. e.g. verifiable proof.

https://catalogue.projectsbyif.com/patterns/verifiable-proof

https://catalogue.projectsbyif.com/patterns/proximity-sharing

https://catalogue.projectsbyif.com/patterns/decision-testing

Trust & Design - projectif.com are riunning trainig.

How do you protect privacy of children.
HOw do you get consent to share medical records?

**A Responsible Development Process**

How are the latest development or not sl lates develpoments in softare development enableing embedding ethics into the development process.

Breaking silos.

Whose problem is a defect in production?

Was it management not funding enough?

Or operations screwed up the deployment somehow?

"My job goes from here to here is a symptom of the problem."

Then we have multi-disciplinary teams, including devops.

Sam: doteveryone.org.uk is a think tank for responsible 

We think developers and product owners have the power. We can create things out of nothing.

But how do you know what to do?

Responsible Technology considers the social impact it creates and seeks to understand and minimise its potential unintended consequecnes.

Responsible technologies:

- do not knowingly create or deepen existing inequalities
- recohgnise and respect dignity and rights
- give people confidence and trust in thei use

This is not an ethical bible but guidelines for responsible use.

Steve - Mitsuku

https://www.amazon.co.uk/Scottish-Clubland-Vol-Various-Artists/dp/B00129XQ68/ref=sr_1_1?ie=UTF8&qid=1531494571&sr=8-1&keywords=scottish+clubland+3

20 visits per day, to 2000 per hour.

Entered competitions in 2010. 

Loebner Prize 2017 - Overall - 1

In 2010, Siri placed 14th,.

Only plsaces that don't are the South Pole and North Korea.

Because it talks to so many people he has to keep it child friendly.

It's designed for general chit-chat.

Supervised learning is very time-consuming.

Unsupervised learning - Tay. 

Mitsuku's attackers. They try to corrupt it but becasue of the supervised learning method.

Obviously it doesn't watch Eastenders because it's computer code.

A weak response encourages a bullying victim interaction.

Find a middle ground.

He does this by issuing a warning system. you get 5 strikes and then you're banned (IP address) for 24 hours.

If you're mean to the bot, the bot will be mean to you. This is a fairly human trait.

It Mitsuku learns something she learns it only for the user who's chatting.

Trolls are getting screen shots put ... it's only for them.

He doesn't want to turn it into a sex bot as it's used by children.

"I'm going to ..." replied with "Well I hope you enjoy yourself."

"I'm going to commit suicide" ... realised he needed to fix that.

A lot of people do think it's alive.

"Do you want to [kill humans]?" "OK I will kill humans."

He looked at a pattern matching bot.

NLP bots tend to be fairly unpredictable.

Uses a language called AIML which is derided by others, but he shows them his medals.

We shouldn't personify robots ... they're machines.

It's software ... it has no gender.

Topic-specific bot - 10,000 ways to ask for a pizza.
Mitsuku - has 350,000 intents.

www.pandorabots.com
@MitsukuChatbot
steve@mitsuku.com
www.mitsuku.com

Coedcode - diversity meetup.

Themes psychological safety.
Facebook would like us to believe that its decisions are deliberate, but they probably aren't.
What do you measure?
How can you allow for unpredictable outcomes?
Building in psychological safety.
Being deliberate about the choices you make.

Jenny Mulholland answering should we start with education or regulation? If we're talking about regulation we need to look at education of MP's.

GDPR seems to have stopped on the genuine people. 

Annie - 3 aspects to policing ethics in tech.
The law
Educating users
Tech companies - getting Google/Apple to buy in

The fourth power are us, techies

Will AI and ML algorithsm in servcies be subject to health and safety algorithms, for which you can be prosecuted. Yes, AI and ML will be subject to helaht and safety legislation.

https://hansard.parliament.uk/Lords/2018-04-24/debates/4348CB2B-8A97-4BA7-B662-8004553E8431/NHSArtificialIntelligence

https://www.parliament.uk/documents/lords-committees/Artificial-Intelligence/AI-Government-Response.pdf

SustainedOSS - unconference later in the year.

Greenwashing and pinkwashing.

Transactivists had been harrassed by Top shop staff (who'd put pink things in their windows).












